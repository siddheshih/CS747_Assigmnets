{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernolli(p):\n",
    "    #np.random.seed(42)\n",
    "    if (np.random.rand() <= p):\n",
    "        return 1.\n",
    "    else:\n",
    "        return 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KLDivergence(x, y):\n",
    "    if (x == 0):\n",
    "        return np.log(1 / (1 - y))\n",
    "    elif (x == 1):\n",
    "        return np.log(1 / y)\n",
    "    else:\n",
    "        return x * np.log(x / y) + (1 - x) * np.log((1 - x) / (1 - y))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_q(p, u, t):\n",
    "    q = 0\n",
    "    RHS = (np.log(t) + 3 * np.log(np.log(t))) / u\n",
    "    i = 0.1\n",
    "    while (i < 1):\n",
    "        LHS = KLDivergence(p, i)\n",
    "        if (LHS <= RHS):\n",
    "            q = i\n",
    "        i += 0.05\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_algorithm(mean_rewards, algorithm, epsilon, horizon):\n",
    "    if (algorithm == \"round-robin\"):\n",
    "        return round_robin(mean_rewards, horizon)\n",
    "    elif (algorithm == \"epsilon-greedy\"):\n",
    "        return epsilon_greedy(mean_rewards, epsilon, horizon)\n",
    "    elif (algorithm == \"ucb\"):\n",
    "        return ucb(mean_rewards, horizon)\n",
    "    elif (algorithm == \"kl-ucb\"):\n",
    "        return kl_ucb(mean_rewards, horizon)\n",
    "    elif (algorithm == \"thompson-sampling\"):\n",
    "        return thompson_sampling(mean_rewards, horizon)\n",
    "    else:\n",
    "        print(\"Enter valid algorithm!\\n\")\n",
    "        exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_robin(mean_rewards, horizon):\n",
    "    # pulls all arms in a round-robin manner\n",
    "    num_arms = len(mean_rewards)\n",
    "    expected_reward = 0\n",
    "    for i in range(horizon):\n",
    "        arm_idx = i % num_arms\n",
    "        reward = pull_arm(mean_rewards[arm_idx])\n",
    "        expected_reward += reward\n",
    "    ideal_reward = max(mean_rewards) * horizon\n",
    "    regret = round(ideal_reward - expected_reward, 3)\n",
    "    return regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(mean_rewards, epsilon, horizon):\n",
    "    num_arms = len(mean_rewards)\n",
    "    calculated_means = [0] * num_arms\n",
    "    num_pulls = [0] * num_arms\n",
    "    expected_reward = 0\n",
    "    for i in range(horizon):\n",
    "        arm_idx = 0\n",
    "        # makes a decision for which arm to pull\n",
    "        decision = np.random.choice([1, 2], p = [epsilon, 1 - epsilon])\n",
    "        if (decision == 1):\n",
    "            # randomly pick an arm to pull\n",
    "            arm_idx = mean_rewards.index(np.random.choice(mean_rewards))\n",
    "        else:\n",
    "            # pick arm with max mean\n",
    "            arm_idx = np.argmax(calculated_means)\n",
    "        reward = pull_arm(mean_rewards[arm_idx])\n",
    "        expected_reward += reward\n",
    "        # calculates the new mean for the pulled arm\n",
    "        calculated_means[arm_idx] = (num_pulls[arm_idx] * calculated_means[arm_idx] + reward) / (num_pulls[arm_idx] + 1)\n",
    "        num_pulls[arm_idx] += 1\n",
    "    ideal_reward = max(mean_rewards) * horizon\n",
    "    regret = round(ideal_reward - expected_reward, 3)\n",
    "    return regret\n",
    "\n",
    "def ucb(mean_rewards, horizon):\n",
    "    num_arms = len(mean_rewards)\n",
    "    calculated_means = [0] * num_arms\n",
    "    num_pulls = [0] * num_arms\n",
    "    ucb_list = [0] * num_arms\n",
    "    expected_reward = 0\n",
    "    # sampling each arm once\n",
    "    for arm in range(num_arms):\n",
    "        reward = pull_arm(mean_rewards[arm])\n",
    "        num_pulls[arm] += 1\n",
    "        calculated_means[arm] = reward\n",
    "    for i in range(num_arms, horizon):\n",
    "        # calculating the UCBs for each arm\n",
    "        for arm in range(num_arms):\n",
    "            p = calculated_means[arm]\n",
    "            u = num_pulls[arm]\n",
    "            ucb_list[arm] = p + np.sqrt(2 * np.log(i) / u)\n",
    "        # picking the arm with maximum UCB\n",
    "        arm_idx = np.argmax(ucb_list)\n",
    "        reward = pull_arm(mean_rewards[arm_idx])\n",
    "        expected_reward += reward\n",
    "        calculated_means[arm_idx] = (num_pulls[arm_idx] * calculated_means[arm_idx] + reward) / (num_pulls[arm_idx] + 1)\n",
    "        num_pulls[arm_idx] += 1\n",
    "    ideal_reward = max(mean_rewards) * horizon\n",
    "    regret = round(ideal_reward - expected_reward, 3)\n",
    "    return regret\n",
    "\n",
    "def kl_ucb(mean_rewards, horizon):\n",
    "    num_arms = len(mean_rewards)\n",
    "    calculated_means = [0] * num_arms\n",
    "    num_pulls = [0] * num_arms\n",
    "    ucb_list = [0] * num_arms\n",
    "    expected_reward = 0\n",
    "    # sampling each arm once\n",
    "    for arm in range(num_arms):\n",
    "        reward = pull_arm(mean_rewards[arm])\n",
    "        num_pulls[arm] += 1\n",
    "        calculated_means[arm] = reward\n",
    "    for i in range(num_arms, horizon):\n",
    "        # calculating the KL-UCBs of the arms\n",
    "        for arm in range(num_arms):\n",
    "            p = calculated_means[arm]\n",
    "            u = num_pulls[arm]\n",
    "            ucb_list[arm] = find_max_q(calculated_means[arm], num_pulls[arm], i)\n",
    "        # picking the arm with maximum KL-UCB\n",
    "        arm_idx = np.argmax(ucb_list)\n",
    "        reward = pull_arm(mean_rewards[arm_idx])\n",
    "        expected_reward += reward\n",
    "        calculated_means[arm_idx] = (num_pulls[arm_idx] * calculated_means[arm_idx] + reward) / (num_pulls[arm_idx] + 1)\n",
    "        num_pulls[arm_idx] += 1\n",
    "    ideal_reward = max(mean_rewards) * horizon\n",
    "    regret = round(ideal_reward - expected_reward, 3)\n",
    "    return regret\n",
    "\n",
    "def thompson_sampling(mean_rewards, horizon):\n",
    "    num_arms = len(mean_rewards)\n",
    "    expected_reward = 0\n",
    "    successes = [0] * num_arms\n",
    "    failures = [0] * num_arms\n",
    "    betas = [0] * num_arms\n",
    "    for i in range(horizon):\n",
    "        for arm in range(num_arms):\n",
    "            \n",
    "            arm_success = successes[arm]\n",
    "            arm_failure = failures[arm]\n",
    "           # picks a number from the Beta distribution with \n",
    "           # alpha = arm_success + 1, beta = arm_failure + 1\n",
    "            betas[arm] = np.random.beta(arm_success + 1, arm_failure + 1)\n",
    "        # picks an arm with the maximum Beta value\n",
    "        arm_idx = np.argmax(betas)\n",
    "        reward = pull_arm(mean_rewards[arm_idx])\n",
    "        if (reward == 0):\n",
    "            # failure occurs with reward 0\n",
    "            failures[arm_idx] += 1\n",
    "        else:\n",
    "            # success occurs with reward 1\n",
    "            successes[arm_idx] += 1\n",
    "        expected_reward += reward\n",
    "    ideal_reward = max(mean_rewards) * horizon\n",
    "    regret = round(ideal_reward - expected_reward, 3)\n",
    "    return regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
